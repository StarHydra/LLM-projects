{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber openpyxl groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6GX3zKGyFAd",
        "outputId": "022707f8-ebdd-4566-8f0d-62e932f239d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.8-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m942.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Collecting groq\n",
            "  Downloading groq-0.36.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting pdfminer.six==20251107 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20251107-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\n",
            "Downloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.36.0-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.3/137.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, groq, pdfplumber\n",
            "Successfully installed groq-0.36.0 pdfminer.six-20251107 pdfplumber-0.11.8 pypdfium2-5.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import openpyxl\n",
        "import json\n",
        "import re\n",
        "import datetime\n",
        "from groq import Groq\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "client = Groq(api_key=GROQ_API_KEY)"
      ],
      "metadata": {
        "id": "jKLZN7sUtI8T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(pdf_path):\n",
        "    #Extracting full text from the PDF\n",
        "    full_text = \"\"\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                full_text += page_text + \"\\n\"\n",
        "    return full_text.strip()"
      ],
      "metadata": {
        "id": "n98XRzKm1X2V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_structured_data(text):\n",
        "    #Using Groq api to extract key-value pairs\n",
        "    prompt = \"\"\"\n",
        "You are an expert data extraction AI specializing in converting unstructured biographical narratives into structured key-value pairs.\n",
        "\n",
        "Given the following text:\n",
        "\n",
        "{text}\n",
        "\n",
        "Your task:\n",
        "- Dynamically identify all factual elements and group them into logical key-value pairs. Keys should be concise and descriptive (e.g., \"First Name\", \"Date of Birth\", \"Current Salary\", \"Certifications 1\").\n",
        "- For values: Use exact original data where possible.\n",
        "  - Dates: Output in YYYY-MM-DD format if mentioned (or infer from context like \"June 15, 2002\" -> \"15-Jun-02\").\n",
        "  - Salaries: Numeric value without commas or currency (e.g., \"350,000 INR\" -> 350000 for salary, separate \"INR\" as \"Salary Currency\").\n",
        "  - Add Company/Organization name as value where there is salary mentioned, add previous, current prefix to the key value depending upon date of joining.\n",
        "  - If no company name is mentioned (or just terms like \"first company\",\"last company\",etc. is used), then keep the value section blank\n",
        "  - Add date of joining and of leaving as and where is mentioned\n",
        "  - Percentages/Scores: Keep as it is (e.g., \"92.5%\" -> 92.5%, \"8.7 on a n-point scale\" -> 8.7 and then add the scale in comment section).\n",
        "  - Keep units in key or value if integral (e.g., \"35 years\" for age).\n",
        "  - For lists like certifications or skills, create sequential keys (e.g., \"Certifications 1\", \"Certifications 2\").\n",
        "  - For certifications or skills, add the certification exam/company in the value.\n",
        "  - For certifications or skills, add the year of certification and marks in the comment section.\n",
        "- For comments: Pull relevant contextual sentences or phrases from the original text using exact wording. Include all descriptive details, explanations, or additional info here. If a section is purely descriptive (e.g., technical skills paragraph), use an empty value and put the full description in comments.\n",
        "- Ensure 100% capture: No summarization, omission, or paraphrasing unless absolutely needed for a clean key-value (e.g., inferring \"Birth City\" from \"born in Jaipur\"). Preserve original sentence structure in comments.\n",
        "- Do not introduce new information.\n",
        "- Output ONLY a valid JSON array of objects in this exact format: [{{\"key\": \"string\", \"value\": \"string or number as string\", \"comments\": \"string\"}}]\n",
        "- Order logically: personal info, professional, education, certifications, skills.\n",
        "\n",
        "Make the JSON parsable and complete.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",  #LLM model used\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt.format(text=text)}],\n",
        "        temperature=0.1,  #For low to no random generated text\n",
        "        max_tokens=3000  #Max value being 7000, since using free tier\n",
        "    )\n",
        "\n",
        "    #Parsing the response as JSON\n",
        "    try:\n",
        "        json_str = response.choices[0].message.content.strip()\n",
        "        if json_str.startswith('```json'):\n",
        "            json_str = json_str[7:-3]  #For removing ```json and ```\n",
        "        elif json_str.startswith('```'):\n",
        "            json_str = json_str[3:-3]  #For removing ```\n",
        "        data = json.loads(json_str)\n",
        "        if not isinstance(data, list):\n",
        "            raise ValueError(\"Not a list\")\n",
        "        return data\n",
        "    except json.JSONDecodeError as e:\n",
        "        raise ValueError(f\"Failed to parse JSON from Groq response: {e}. Response: {response.choices[0].message.content}\")"
      ],
      "metadata": {
        "id": "_QlZJ6fbuexj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_date(value):\n",
        "    #Parsing a date string and return datetime.date, else returning original data.\n",
        "    if not isinstance(value, str):\n",
        "        return value\n",
        "    value = value.strip()\n",
        "\n",
        "    #List of possible date formats\n",
        "    fmts = [\"%d-%m-%Y\", \"%d/%m/%Y\", \"%Y-%m-%d\", \"%d-%b-%Y\", \"%d-%B-%Y\"]\n",
        "\n",
        "    for fmt in fmts:\n",
        "        try:\n",
        "            return datetime.datetime.strptime(value, fmt).date()\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "    return value"
      ],
      "metadata": {
        "id": "mekiEjNF3X9s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_excel_output(data, output_path):\n",
        "    #Storing extracted data in excel file\n",
        "    wb = openpyxl.Workbook()\n",
        "    ws = wb.active\n",
        "    ws.title = \"Output\"\n",
        "\n",
        "    ws.append([\"Sr No.\", \"Key\", \"Value\", \"Comments\"]) #Header row\n",
        "\n",
        "    for row_idx, item in enumerate(data, start=2):\n",
        "        ws.cell(row=row_idx, column=1, value=row_idx - 1)  # Sr no.\n",
        "        ws.cell(row=row_idx, column=2, value=item.get(\"key\", \"\"))\n",
        "\n",
        "        raw_value = item.get(\"value\", \"\")\n",
        "        excel_value = parse_date(raw_value)\n",
        "        cell = ws.cell(row=row_idx, column=3, value=excel_value)\n",
        "        if isinstance(excel_value, datetime.date):\n",
        "            cell.number_format = \"DD-MMM-YY\"\n",
        "\n",
        "        ws.cell(row=row_idx, column=4, value=item.get(\"comments\", \"\"))\n",
        "\n",
        "    wb.save(output_path)\n",
        "    print(f\"Excel file saved to {output_path}\")"
      ],
      "metadata": {
        "id": "UcGKA2Sk3Yat"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_comment(original_file):\n",
        "  output_file   = '/content/Output.xlsx'\n",
        "\n",
        "  df = pd.read_excel(original_file)\n",
        "  comments = df['Comments'].fillna('').astype(str).str.strip()\n",
        "\n",
        "  #Removing duplicates while keep the last occurrence of identical comments\n",
        "  df['Comments'] = df['Comments'].where(~df['Comments'].duplicated(keep='last'), '')\n",
        "\n",
        "  comments = df['Comments'].copy()\n",
        "  for i in range(len(df)):\n",
        "      if not comments[i]:\n",
        "          continue\n",
        "      current = comments[i].lower()\n",
        "      for j in range(len(df)):\n",
        "          if i != j and comments[j] and current in comments[j].lower():\n",
        "              if len(comments[i]) <= len(comments[j]):  #Removing comments that are substrings of longer ones\n",
        "                  df.at[i, 'Comments'] = ''\n",
        "                  break\n",
        "\n",
        "  from openpyxl import load_workbook\n",
        "\n",
        "  wb = openpyxl.load_workbook(original_file)\n",
        "  ws = wb.active\n",
        "\n",
        "  #Writing only the comments column\n",
        "  for row_idx, comment in enumerate(df['Comments'], start=2):\n",
        "      ws.cell(row=row_idx, column=4).value = comment if comment else None\n",
        "\n",
        "  wb.save(output_file)\n",
        "  print(\"Cleaning completed\")"
      ],
      "metadata": {
        "id": "Co-5kQd6tpPz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    pdf_path = '/content/Data_Input.pdf'\n",
        "\n",
        "    print(\"Extracting text from PDF...\")\n",
        "    text = extract_text(pdf_path)\n",
        "    print(\"Text extracted successfully.\")\n",
        "    #print(f\"Extracted text preview: {text[:500]}...\") #For preview/debugging\n",
        "\n",
        "    print(\"Extracting key-value pairs using Groq...\")\n",
        "    structured_data = extract_structured_data(text)\n",
        "    print(f\"Extracted {len(structured_data)} key-value pairs.\")\n",
        "\n",
        "    #For previewing/debugging key:value:comment\n",
        "    #for item in structured_data:\n",
        "        #print(f\"Key: {item['key']}, Value: {item['value']}, Comments: {item['comments'][:100]}...\")\n",
        "\n",
        "    output_path = '/content/Output_1.xlsx'\n",
        "    create_excel_output(structured_data, output_path)\n",
        "    print(\"Excel file created successfully.\")\n",
        "    clean_comment(output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKVEBgyntpBT",
        "outputId": "bde4a525-880e-4840-f3c7-abec631b5ee5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting text from PDF...\n",
            "Text extracted successfully.\n",
            "Extracting key-value pairs using Groq...\n",
            "Extracted 44 key-value pairs.\n",
            "Excel file saved to /content/Output_1.xlsx\n",
            "Excel file created successfully.\n",
            "Cleaning completed\n"
          ]
        }
      ]
    }
  ]
}